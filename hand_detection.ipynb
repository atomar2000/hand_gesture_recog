{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imutils\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "bg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "print(pickle.format_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_avg(image , aWeight):\n",
    "    global bg\n",
    "    if bg is None:\n",
    "        bg = image.copy().astype('float')\n",
    "        return \n",
    "    cv2.accumulateWeighted(image, bg , aWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(image, threshold = 40):\n",
    "    diff = cv2.absdiff(bg.astype('uint8') , image)\n",
    "    cv2.imshow(\"diff\", diff)\n",
    "    thresholded = cv2.threshold(image.copy(),threshold, 255 , cv2.THRESH_BINARY)[1]\n",
    "    thresholded = cv2.threshold(diff,threshold, 255 , cv2.THRESH_BINARY)[1]\n",
    "    cv2.imshow(\"thresholded\", thresholded)\n",
    "    (cnts, _) = cv2.findContours(thresholded.copy() , cv2.RETR_EXTERNAL , cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #(cnts, _) = cv2.findContours(diff.copy() , cv2.RETR_EXTERNAL , cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(cnts) == 0:\n",
    "        return\n",
    "    else:\n",
    "        segmented = max(cnts, key = cv2.contourArea)\n",
    "        return (diff , segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is Data\n",
      " Volume Serial Number is 305E-8A43\n",
      "\n",
      " Directory of D:\\git\\hand_gesture_recog\\hand_gesture\n",
      "\n",
      "19-11-2020  12:30    <DIR>          .\n",
      "19-11-2020  12:30    <DIR>          ..\n",
      "05-11-2020  13:11    <DIR>          .ipynb_checkpoints\n",
      "05-11-2020  11:58         6,369,966 _model_.sav\n",
      "06-11-2020  05:24    <DIR>          HAND_DETECTION\n",
      "19-11-2020  12:30             8,121 hand_detection.ipynb\n",
      "06-11-2020  05:26            44,663 hand_recog_model.ipynb\n",
      "               3 File(s)      6,422,750 bytes\n",
      "               4 Dir(s)  794,513,149,952 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = r'D:\\datasets\\archive\\leapGestRecog\\0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = {'01_palm': 0,\n",
    " '02_l': 1,\n",
    " '03_fist': 2,\n",
    " '04_fist_moved': 3,\n",
    " '05_thumb': 4,\n",
    " '06_index': 5,\n",
    " '07_ok': 6,\n",
    " '08_palm_moved': 7,\n",
    " '09_c': 8,\n",
    " '10_down': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01_palm': 0,\n",
       " '02_l': 1,\n",
       " '03_fist': 2,\n",
       " '04_fist_moved': 3,\n",
       " '05_thumb': 4,\n",
       " '06_index': 5,\n",
       " '07_ok': 6,\n",
       " '08_palm_moved': 7,\n",
       " '09_c': 8,\n",
       " '10_down': 9}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01_palm': 0,\n",
       " '02_l': 1,\n",
       " '03_fist': 2,\n",
       " '04_fist_moved': 3,\n",
       " '05_thumb': 4,\n",
       " '06_index': 5,\n",
       " '07_ok': 6,\n",
       " '08_palm_moved': 7,\n",
       " '09_c': 8,\n",
       " '10_down': 9}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup = dict()\n",
    "reverselookup = dict()\n",
    "count = 0\n",
    "for j in os.listdir(loc + str(0)):\n",
    "    if not j.startswith('.'):                              \n",
    "        lookup[j] = count\n",
    "        reverselookup[count] = j\n",
    "        count = count + 1\n",
    "lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":    \n",
    "    aWeight = 0.2    \n",
    "    camera = cv2.VideoCapture(0)    \n",
    "    model = tf.keras.models.load_model('HAND_DETECTION')\n",
    "    top, right, bottom, left = 10, 350, 225, 590    \n",
    "    num_frames = 0  \n",
    "    predict_img = None\n",
    "    result = None\n",
    "    while(True):       \n",
    "        (grabbed, frame) = camera.read()        \n",
    "        frame = cv2.flip(frame, 1)        \n",
    "        \n",
    "        clone = frame.copy()       \n",
    "        (height, width) = frame.shape[:2]        \n",
    "        roi = frame[top:bottom, right:left]    \n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        #gray = cv2.GaussianBlur(gray, (7,7), 0)              \n",
    "        cv2.imshow(\"before avg\", gray)\n",
    "        if num_frames < 50:\n",
    "            run_avg(gray, aWeight)\n",
    "        else:           \n",
    "            hand = segment(gray)            \n",
    "            if hand is not None:                \n",
    "                (thresholded, segmented) = hand                \n",
    "                cv2.drawContours(clone, [segmented + (right, top)], -1, (255, 142, 77) , 3)\n",
    "                predict_img = thresholded      \n",
    "                #predict_img = cv2.resize(predict_img , (120,320))\n",
    "                predict_img = cv2.resize(predict_img , (320,120))\n",
    "                cv2.imshow(\"image prediction img\", predict_img)\n",
    "                predict_img = np.array(predict_img, dtype = 'float32')\n",
    "                y_pred = model.predict(predict_img.reshape(1,120,320,1))\n",
    "                result = np.argmax(y_pred)\n",
    "                \n",
    "                result = reverselookup[result]               \n",
    "                 \n",
    "                \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX        \n",
    "        #color = (255, 255, 255)\n",
    "        color = (0, 0, 0)\n",
    "        i = 0\n",
    "        cv2.putText(clone,result,(350, 250),font, 1,color,2,cv2.LINE_AA)\n",
    "            \n",
    "            \n",
    "        cv2.rectangle(clone, (left, top), (right, bottom), (0,255,0), 2)        \n",
    "        num_frames += 1   \n",
    "         \n",
    "        \n",
    "        #print(result)\n",
    "        cv2.imshow(\"Video Feed\", clone)        \n",
    "        keypress = cv2.waitKey(1)       \n",
    "        if keypress == ord(\"q\"):\n",
    "            break\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
